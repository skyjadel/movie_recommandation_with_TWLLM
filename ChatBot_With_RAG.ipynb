{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95697674-414e-4120-a1e3-8b0b56e28750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline, StoppingCriteria\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c941462-8ffb-4371-83e9-005743fbad0e",
   "metadata": {},
   "source": [
    "這邊使用的推薦系統是根據 <a href=\"https://grouplens.org/datasets/movielens/\">https://grouplens.org/datasets/movielens/</a>\n",
    "的 25M-MovieLens 資料所建造的 <br>\n",
    "這個資料集的資料最新到 2019，所以這裡的推薦系統無法推薦更新的電影 <br>\n",
    "執行這個程式所需資料包括：<br>\n",
    "./hundred_likers.csv<br>\n",
    "./best_300.csv<br>\n",
    "./cross_scores.db<br>\n",
    "這三個檔案<br>\n",
    "它們主要是我使用 ./Recommandation_cross_score_calculation.ipynb 與 ./Recommandation_cross_score_calculation.ipynb 兩個筆記本整理計算而成<br>\n",
    "其中 ./best_300.csv 裡面的中文片名，則是我另外手動填上的<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54de4c6-be33-418a-8259-9b3075c91f5d",
   "metadata": {},
   "source": [
    "這邊我使用的 LLM 基底是 Llama-3-Taiwan 的 8B-128k 版本，這是一個專門針對繁體中文資料優化過的 Llmam-3 模型。<br>\n",
    "由於這個模型在 huggingface 上需要同意一些簡單的條件才能下載，所以如果你想自己執行這個程式，<br>\n",
    "你必須先註冊一個 huggingface 帳號，取得跟你帳號綁定的 token，<br>\n",
    "並且到  <a href=\"https://huggingface.co/yentinglin/Llama-3-Taiwan-8B-Instruct-128k\">https://huggingface.co/yentinglin/Llama-3-Taiwan-8B-Instruct-128k</a> 取得授權，<br>\n",
    "才能下載這個模型 <br>\n",
    "另外，如果要在GPU上執行這個模型，那VRAM最好需要20GB以上比較保險。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d7cd8-79ea-48dd-a4d7-8632dc0712aa",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf79d8e-3971-40d2-80af-d45ff07f61b0",
   "metadata": {},
   "source": [
    "## 初始化 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf62b9cd-ebd1-4134-b436-efd1f9469853",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./huggingface/read-only-token.txt', 'r') as f:\n",
    "    token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb78d80-ce89-42dd-bad4-308302de9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom stopping criteria class\n",
    "class EosListStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, eos_sequence=[128256]):\n",
    "        self.eos_sequence = eos_sequence\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        last_ids = input_ids[:, -len(self.eos_sequence):].tolist()\n",
    "        return self.eos_sequence in last_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0611f534-f789-4333-ab12-e896d4548229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d3051fe1ce4616a0bc2e06330386cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"yentinglin/Llama-3-Taiwan-8B-Instruct-128k\"\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model_name, device_map=device, torch_dtype=torch.bfloat16, token=token)\n",
    "tokenizer = llm.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ae79d-8af7-4979-8206-a19df5780dcd",
   "metadata": {},
   "source": [
    "## ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af910e3-2fa1-40c5-a72d-6805308b417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對話機器人\n",
    "class Chat():\n",
    "    def __init__(self):\n",
    "        self.role = [{\"role\": \"system\", \"content\": \"You are an AI assistant called Twllm, created by TAME (TAiwan Mixture of Expert) project.\"},]\n",
    "        self.chat = deepcopy(self.role)\n",
    "        self.recent_movie_recommand = False\n",
    "        self.robot_name = 'Twllm' #對話機器人的名字\n",
    "\n",
    "    def text_generator(self, chat, temperature=0.7):\n",
    "        flatten_chat_for_generation = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "        with torch.no_grad():\n",
    "            output = llm(flatten_chat_for_generation, \n",
    "                         return_full_text=False, \n",
    "                         max_new_tokens=768,\n",
    "                         temperature=temperature, \n",
    "                         stopping_criteria=[EosListStoppingCriteria([tokenizer.eos_token_id])])\n",
    "        return output[0]['generated_text']\n",
    "\n",
    "    def request_of_film_recommandation(self, input_text):\n",
    "        for k in range(3):\n",
    "            justify = self.text_generator(self.role + [{\"role\": \"user\",\n",
    "                                                        \"content\": (f\"當使用者說出「{input_text}」的時候，他是在請你推薦電影嗎？請回答「是」，「否」，或「不確定」。\")}],\n",
    "                                          temperature=0.1)\n",
    "            if not '是' in justify[0:min(len(justify), 3)]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # def say_goodbye(self, input_text):\n",
    "    #     justify = self.text_generator(self.role + [{\"role\": \"user\",\n",
    "    #                                                 \"content\": (f\"當有人說出「{input_text}」的時候，他是在表達要結束對話嗎？請回答「是」，「否」，或「不確定」。\")}],\n",
    "    #                                   temperature=0.1)\n",
    "    #     return '是' in justify[0:min(len(justify), 3)]\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            input_text = input('你：')\n",
    "            self.chat.append({\"role\": \"user\", \"content\": input_text})\n",
    "            if self.request_of_film_recommandation(input_text) and (not self.recent_movie_recommand):\n",
    "                movie_recommander = Movie_Recommander()\n",
    "                output_text = movie_recommander.run()\n",
    "                self.chat += movie_recommander.movie_discuss_chat[1::]\n",
    "                self.recent_movie_recommand = True\n",
    "                if output_text is None:\n",
    "                    output_text = self.text_generator(self.chat)\n",
    "            else:\n",
    "                output_text = self.text_generator(self.chat)\n",
    "                self.recent_movie_recommand = False\n",
    "            self.chat.append({\"role\": \"assistant\", \"content\": output_text})\n",
    "            print('='*30)\n",
    "            print(f\"{self.robot_name}：{output_text}\")\n",
    "            if '再見' in output_text or 'bye' in output_text.lower():\n",
    "                break\n",
    "            print('='*30)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebed88e-ae21-413f-bf2b-4c43401b237c",
   "metadata": {},
   "source": [
    "## 推薦系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26a823a-b31b-4c47-bcb1-005f10762389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Movie_Recommander(Chat):\n",
    "    def __init__(self, chat=None):\n",
    "        super().__init__()\n",
    "        self.best_300 = pd.read_csv('./best_300.csv')\n",
    "        self.sql_path = './cross_scores.db'\n",
    "        self.hundred_likers = pd.read_csv('./hundred_likers.csv')\n",
    "        self.ideal_movie_recommandation_number = 7\n",
    "        self.minimum_movie_recommandation_base = 3\n",
    "        self.maximum_movie_recommandation_base = 14\n",
    "        if chat is None:\n",
    "            self.movie_discuss_chat = deepcopy(self.role)\n",
    "        else:\n",
    "            self.movie_discuss_chat = chat\n",
    "\n",
    "    def ask(self, n_film=25):\n",
    "        self.random_selected_df =\\\n",
    "        self.best_300.loc[random.sample(list(self.best_300.index), k=n_film)].reset_index(drop=True).drop(['Liker_num', 'Liker_ratio'], axis=1)\n",
    "        output_text = f'{self.robot_name}：我需要知道你喜歡什麼電影，請在以下電影當中，選擇 1~3 部你喜歡的電影：\\n\\n'\n",
    "        context_text = ''\n",
    "        self.ask_lines = []\n",
    "        for i in self.random_selected_df.index:\n",
    "            movieId = self.random_selected_df.loc[i, 'Movie_id']\n",
    "            eng_title = self.random_selected_df.loc[i, 'Movie']\n",
    "            tw_title = self.random_selected_df.loc[i, 'Taiwan Film Name'].strip(' ')\n",
    "            year = self.random_selected_df.loc[i, 'Year']\n",
    "\n",
    "            output_text += f'  -{tw_title} ({eng_title}) ({year})\\n'\n",
    "            self.ask_lines.append(f'  -{tw_title} ({eng_title}) ({year})'.replace(' ', ''))\n",
    "            context_text += f'(ID: {movieId}, \"{tw_title}\", \"{eng_title}\")|||\\n'\n",
    "        print('='*30)\n",
    "        print(output_text)\n",
    "        self.movie_discuss_chat += [{'role': 'context', 'content': context_text}]\n",
    "        self.movie_discuss_chat += [{'role': 'assistant', 'content': output_text[3::]}]\n",
    "        print('='*30)\n",
    "        answer = input('你：')\n",
    "        self.movie_discuss_chat += [{'role': 'user', 'content': answer}]\n",
    "\n",
    "    def find_IDs(self, answer):\n",
    "        sub_titles = self.text_generator(self.movie_discuss_chat +\\\n",
    "                                     [{'role': 'directive', 'content': f'請找出這段文字當中的電影名稱，用逗號分隔回傳。:{answer}'}])\n",
    "        sub_titles = [s.replace(' ', '') for s in sub_titles.split(',')]\n",
    "\n",
    "        IDs = []\n",
    "        input_titles = []\n",
    "        for sub_title in sub_titles:\n",
    "            for i, line in enumerate(self.ask_lines):\n",
    "                if sub_title in line:\n",
    "                    IDs.append(self.random_selected_df.loc[i, 'Movie_id'])\n",
    "                    input_titles.append(self.random_selected_df.loc[i, 'Taiwan Film Name'])\n",
    "                    break\n",
    "        return IDs, input_titles\n",
    "\n",
    "    def adjust_score(self, a_diff):\n",
    "        def func(df):\n",
    "            df['F_score'] += a_diff * (np.log(np.array(df['P_boost'])+1e-4) - np.log(np.array([max(1, j) for j in df['N_boost']]))) / np.log(10)\n",
    "            return df\n",
    "        return func\n",
    "\n",
    "    def get_recommandation_scores_from_one_movie(self, movieId, save_unrelated_movies=True, adjust_score=None):\n",
    "        conn = sqlite3.connect(self.sql_path)\n",
    "        cursor = conn.cursor()\n",
    "        sql_command = f'SELECT * FROM cross_score WHERE Movie_ID_A = {movieId}'\n",
    "        cursor.execute(sql_command)\n",
    "        result = cursor.fetchall()\n",
    "    \n",
    "        keys = ('ID_A', 'ID_B', 'P_boost', 'N_boost', 'P_condition', 'N_condition', 'A_condition', 'F_score')\n",
    "        dict_to_df = {key:[] for key in keys}\n",
    "        for row in result:\n",
    "            for i in range(len(keys)):\n",
    "                dict_to_df[keys[i]].append(row[i])\n",
    "            if save_unrelated_movies:\n",
    "                if dict_to_df['F_score'][-1] < -9000:\n",
    "                    if dict_to_df['P_boost'][-1] >= dict_to_df['N_boost'][-1] and dict_to_df['P_condition'][-1] >= dict_to_df['N_condition'][-1] * 2:\n",
    "                        dict_to_df['F_score'][-1] = -1\n",
    "            \n",
    "                #dict_to_df = adjust_score(dict_to_df)\n",
    "        the_df = pd.DataFrame(dict_to_df)\n",
    "        if not adjust_score is None:\n",
    "            the_df = adjust_score(the_df)\n",
    "        return the_df.sort_values('ID_B')\n",
    "\n",
    "    def get_recommandation_IDs_from_movies(self, movieIds, method='A', adjust_a=0, return_scores=False):\n",
    "        ideal_n_movies = self.ideal_movie_recommandation_number\n",
    "        min_n_movies = self.minimum_movie_recommandation_base\n",
    "        max_n_movies = self.maximum_movie_recommandation_base\n",
    "        def select_and_pop():\n",
    "            L = []\n",
    "            for i in range(len(ds)):\n",
    "                if not i in candidate_dict.keys():\n",
    "                    L.append(0)\n",
    "                    continue\n",
    "                if len(candidate_dict[i]) == 0:\n",
    "                    L.append(0)\n",
    "                    continue\n",
    "                L.append(max([j[1] for j in candidate_dict[i]]))\n",
    "            this_c = np.argmax(L)\n",
    "            this_m = candidate_dict[this_c].pop(0)\n",
    "            selected_movies[this_c].append(this_m)\n",
    "            for j in candidate_dict.keys():\n",
    "                for k in range(len(candidate_dict[j])):\n",
    "                    if candidate_dict[j][k][0] == this_m[0]:\n",
    "                        _ = candidate_dict[j].pop(k)\n",
    "                        break\n",
    "        \n",
    "        if not type(movieIds) == list:\n",
    "            movieIds = [movieIds]\n",
    "\n",
    "        eff_movieIds = []\n",
    "        for i in movieIds:\n",
    "            if i in list(self.best_300['Movie_id']):\n",
    "                eff_movieIds.append(i)\n",
    "        \n",
    "        if len(eff_movieIds) == 0:\n",
    "            return None\n",
    "        \n",
    "        if adjust_a == 0:\n",
    "            ds = [self.get_recommandation_scores_from_one_movie(i) for i in eff_movieIds]\n",
    "        else:\n",
    "            ds = [self.get_recommandation_scores_from_one_movie(i, adjust_score=self.adjust_score(adjust_a)) for i in eff_movieIds]\n",
    "        n_candidates_each_df = int(np.ceil(max_n_movies / len(eff_movieIds)))\n",
    "        n_suggestion_each_df = int(min_n_movies / len(eff_movieIds))\n",
    "        \n",
    "        if len(ds) > 1:\n",
    "            for j in range(1, len(ds)):\n",
    "                if j == 1:\n",
    "                    D = pd.merge(ds[j-1], ds[j], on = 'ID_B', suffixes=[f'_{j-1}', f'_{j}'])\n",
    "                else:\n",
    "                    D = pd.merge(D, ds[j], on = 'ID_B').rename(columns={'F_score': f'F_score_{j}'})\n",
    "        \n",
    "            for j in range(len(ds)):\n",
    "                D = D[D[f'F_score_{j}'] >= 0]\n",
    "                D = D[D['ID_B'] != eff_movieIds[j]]\n",
    "    \n",
    "            candidate_dict = {}\n",
    "            for i in range(len(ds)):\n",
    "                this_D = D.sort_values(f'F_score_{i}', ascending=False).iloc[0:n_candidates_each_df]\n",
    "                candidate_dict[i] = [list(this_D.iloc[j][['ID_B', f'F_score_{i}']]) for j in range(len(this_D))]\n",
    "            if method == 'A':\n",
    "                result_set = set(D.sort_values('F_score_0', ascending=False).iloc[0:n_candidates_each_df]['ID_B'])\n",
    "                for j in range(1, len(ds)):\n",
    "                    result_set = result_set.union(set(D.sort_values(f'F_score_{j}', ascending=False).iloc[0:n_candidates_each_df]['ID_B']))\n",
    "                #result_list = list(result_set)\n",
    "                final_df = pd.DataFrame({'ID':[], 'Score':[]})\n",
    "                for ID in result_set:\n",
    "                    this_df = pd.DataFrame({'ID':[ID], 'Score':max(list(D[D['ID_B']==ID][[f'F_score_{j}' for j in range(len(ds))]].iloc[0]))})\n",
    "                    final_df = pd.concat([final_df, this_df])\n",
    "                final_df = final_df.sort_values('Score', ascending=False)[0:min(len(final_df), ideal_n_movies)]\n",
    "            elif method == 'B':\n",
    "                candidate_dict = {}\n",
    "                for i in range(len(ds)):\n",
    "                    this_D = D.sort_values(f'F_score_{i}', ascending=False).iloc[0:n_candidates_each_df]\n",
    "                    candidate_dict[i] = [list(this_D.iloc[j][['ID_B', f'F_score_{i}']]) for j in range(len(this_D))]\n",
    "                selected_movies = {i:[] for i in range(len(ds))}\n",
    "                while sum([len(v) for v in selected_movies.values()]) < ideal_n_movies and sum([len(v) for v in candidate_dict.values()]) > 0:\n",
    "                    select_and_pop()\n",
    "                \n",
    "                remaining_keys = [k for k in candidate_dict.keys()]\n",
    "                for i in remaining_keys:\n",
    "                    if len(selected_movies[i]) >= n_suggestion_each_df:\n",
    "                        _ = candidate_dict.pop(i)\n",
    "                \n",
    "                while min([len(v) for v in selected_movies.values()]) < n_suggestion_each_df and sum([len(v) for v in candidate_dict.values()]) > 0:\n",
    "                    select_and_pop()\n",
    "                #print(selected_movies)\n",
    "                final_df = {'ID':[], 'Score':[]}\n",
    "                for k in selected_movies.keys():\n",
    "                    for j in range(len(selected_movies[k])):\n",
    "                        final_df['ID'].append(selected_movies[k][j][0])\n",
    "                        final_df['Score'].append(selected_movies[k][j][1])\n",
    "                final_df = pd.DataFrame(final_df)\n",
    "                final_df = final_df.sort_values('Score', ascending=False)\n",
    "                \n",
    "        else:\n",
    "            final_df = ds[0][['ID_B', 'F_score']].rename(columns={'F_score': 'Score', 'ID_B': 'ID'})\n",
    "            final_df = final_df.sort_values('Score', ascending=False)[0:min(len(final_df), ideal_n_movies)]\n",
    "        final_id_list = [int(s) for s in final_df['ID']]\n",
    "        final_scores = list(final_df['Score'])\n",
    "        if return_scores:\n",
    "            return final_id_list, final_scores\n",
    "        return final_id_list\n",
    "\n",
    "    def get_titles_from_IDs(self, ids):\n",
    "        movies_titles = []\n",
    "        for i in ids:\n",
    "            movies_titles.append(self.hundred_likers[self.hundred_likers['Movie_id'] == i]['Movie'].iloc[0])\n",
    "        return movies_titles\n",
    "\n",
    "    def recommand(self, movies_titles, input_titles):\n",
    "        movies_titles = ', '.join(movies_titles)\n",
    "        this_chat = self.role + [{'role': 'directive', 'content': (f'你要推薦這幾部電影給使用者:{movies_titles}，而不要推薦他已經告訴你他喜歡的電影。'\n",
    "                                                                         f'你要告訴使用者，你是根據他喜歡的電影，為他量身訂製這一份片單，'\n",
    "                                                                        '並為每一部你推薦的電影寫50字以內的推薦文。')}]\n",
    "        output_text = self.text_generator(this_chat, temperature=0.3)\n",
    "        return output_text\n",
    "\n",
    "    def run(self):\n",
    "        self.ask()\n",
    "        input_IDs, input_titles= self.find_IDs(self.movie_discuss_chat[-1]['content'])\n",
    "        ans_IDs = self.get_recommandation_IDs_from_movies(input_IDs, method='B', adjust_a=5)\n",
    "        if ans_IDs is None:\n",
    "            return None\n",
    "        ans_titles = self.get_titles_from_IDs(ans_IDs)\n",
    "        output_text = self.recommand(ans_titles, input_titles)\n",
    "        return output_text\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a04942-a03a-4a5a-ab89-612f8909c6bf",
   "metadata": {},
   "source": [
    "# 執行對話機器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b101756-93ed-46e3-8ac5-dd77a5735746",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a166765-5aa6-4001-9b25-32fd9dfbd840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "你： 你好，請問你是誰？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skyja\\anaconda3\\envs\\taipower\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:648: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Twllm：我是一個開源人工智能助理，我很樂意為您提供幫助。我可以回答您的問題，幫助您完成任務，與您交談等等。您想問我什麼呢？\n",
      "==============================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "你： 我想請你推薦電影\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Twllm：我需要知道你喜歡什麼電影，請在以下電影當中，選擇 1~3 部你喜歡的電影：\n",
      "\n",
      "  -神鬼無間 (The Departed) (2006)\n",
      "  -美女與野獸 (Beauty and the Beast) (1991)\n",
      "  -聖戰奇兵 (Indiana Jones and the Last Crusade) (1989)\n",
      "  -大英雄天團 (Big Hero 6) (2014)\n",
      "  -空前絕後滿天飛 (Airplane!) (1980)\n",
      "  -雲端情人 (Her) (2013)\n",
      "  -明日邊界 (Edge of Tomorrow) (2014)\n",
      "  -幸福綠皮書 (Green Book) (2018)\n",
      "  -刺激驚爆點 (The Usual Suspects) (1995)\n",
      "  -哈利波特：消失的密室 (Harry Potter and the Chamber of Secrets) (2002)\n",
      "  -魔鬼剋星 (Ghostbusters) (1984)\n",
      "  -今天暫時停止 (Groundhog Day) (1993)\n",
      "  -衝出寧靜號 (Serenity) (2005)\n",
      "  -哈利波特：混血王子的背叛 (Harry Potter and the Half-Blood Prince) (2009)\n",
      "  -星際異攻隊2 (Guardians of the Galaxy 2) (2017)\n",
      "  -醉後大丈夫 (The Hangover) (2009)\n",
      "  -北非諜影 (Casablanca) (1942)\n",
      "  -侏羅紀公園 (Jurassic Park) (1993)\n",
      "  -哈比人：意外旅程 (The Hobbit: An Unexpected Journey) (2012)\n",
      "  -超人特攻隊2 (Incredibles 2) (2018)\n",
      "  -莎翁情史 (Shakespeare in Love) (1998)\n",
      "  -神鬼奇航：鬼盜船魔咒 (Pirates of the Caribbean: The Curse of the Black Pearl) (2003)\n",
      "  -神鬼認證：神鬼疑雲 (The Bourne Supremacy) (2004)\n",
      "  -驚魂記 (Psycho) (1960)\n",
      "  -2009月球漫遊 (Moon) (2009)\n",
      "\n",
      "==============================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "你： 神鬼無間  神鬼奇航：鬼盜船魔咒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Twllm：根據你喜歡的電影，我為你精心挑選了這些電影。讓我們開始吧！\n",
      "\n",
      "1. Sherlock Holmes (2009) - 這部電影是一部充滿智慧和懸疑的驚悚片，講述了著名偵探福爾摩斯和他的夥伴華生醫生的冒險故事。由羅伯特·唐尼和裘德·洛主演，這部電影是一個很好的選擇，適合喜歡動作和智慧的電影愛好者。\n",
      "2. Seven (a.k.a. Se7en) (1995) - 這部電影是一部心理驚悚片，講述了一名偵探和一名年輕警官合作，追捕一名正在進行一系列殘忍犯罪的罪犯。由布萊德·彼特和摩根·弗里曼主演，這部電影是一個很好的選擇，適合喜歡緊張和懸疑的電影愛好者。\n",
      "3. Casino (1995) - 這部電影是一部犯罪劇，講述了一名在賭城工作的拉斯維加斯高利拉斯的故事。由馬丁·斯科塞斯執導，由羅伯特·迪尼羅、謝爾·加德納和凱西·貝茨主演，這部電影是一個很好的選擇，適合喜歡劇情和角色發展的電影愛好者。\n",
      "4. X-Men (2000) - 這部電影是一部超級英雄動作片，講述了一群具有超能力的英雄對抗一個試圖消滅他們的壞人。由休·傑克曼、伊恩·麥克連和派翠西亞·克拉克主演，這部電影是一個很好的選擇，適合喜歡動作和冒險的電影愛好者。\n",
      "5. Ocean's Eleven (2001) - 這部電影是一部犯罪喜劇，講述了一群專業小偷計劃在拉斯維加斯的豪華賭場進行大膽搶劫。由史蒂芬·索德伯格執導，由喬治·克隆尼、布魯斯·威利斯和凱特·哈德森主演，這部電影是一個很好的選擇，適合喜歡幽默和娛樂的電影愛好者。\n",
      "6. Goodfellas (1990) - 這部電影是一部劇情片，講述了一名年輕人加入黑幫家族並逐漸崛起的故事。由馬丁·斯科塞斯執導，由勞勃·迪尼羅、約翰·特拉沃爾塔和凱特·卡林主演，這部電影是一個很好的選擇，適合喜歡劇情和角色發展的電影愛好者。\n",
      "7. Iron Man (2008) - 這部電影是一部超級英雄動作片，講述了一名億萬富翁發明家建造了一套強大的裝甲套裝並利用它來對抗一個敵對國家的故事。由強·法夫洛執導，由羅伯特·唐尼、格溫妮絲·帕特洛和唐·錢德爾主演，這部電影是一個很好的選擇，適合喜歡動作和冒險的電影愛好者。\n",
      "\n",
      "希望你喜歡這些電影！\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f78b75-7bd0-4167-9a5f-e1b5e3b23d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
